<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Spectral Decompositions of Adjacency Matrices</title>
  <meta name="description" content="In this post, my goal is to establish why the adjacency matrix of a simple graph has its spectral decomposition; in my previous posts up until this point, I ...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2016/09/05/spectral-decompositions-of-adjacency-matrices.html">
  <link rel="alternate" type="application/rss+xml" title="Mark Farrell" href="/feed.xml">

  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  
  
</head>

  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">Mark Farrell</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Spectral Decompositions of Adjacency Matrices</h1>
    <p class="post-meta"><time datetime="2016-09-05T00:00:00-04:00" itemprop="datePublished">Sep 5, 2016</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>In this post, my goal is to establish why the adjacency matrix of a simple graph has its spectral decomposition; in my previous posts up until this point, I have relied on the fact that the adjacency matrix of a simple graph has its spectral decomposition, and related facts, without examining or justifying that these facts are true directly. Stated more precisely, my goal for this post is to justify that the adjacency matrix <script type="math/tex">A</script> of any simple graph has the spectral decomposition <script type="math/tex">A = \sum\limits_{\lambda \in \sigma(A)} \lambda E_\lambda</script>, where <script type="math/tex">\sigma(A)</script> denotes the set of distinct eigenvalues of <script type="math/tex">A</script>, and <script type="math/tex">E_\lambda</script> denotes an orthogonal projection onto the eigenspace of <script type="math/tex">\lambda</script> for all <script type="math/tex">\lambda \in \sigma(A)</script>. It turns out that the adjacency matrix of a simple graph has its spectral decomposition because it is a real symmetric matrix, and any real symmetric matrix has its spectral decomposition; so, I would like to focus somewhat more generally on establishing why any real symmetric matrix has a spectral decomposition, despite the spectral decomposition of the adjacency matrix of a simple graph being of particular relevance to the current subject matter of this blog.</p>

<p>Suppose that <script type="math/tex">A</script> is a <script type="math/tex">d</script> x <script type="math/tex">d</script> real symmetric matrix. Then, in this context, I would propose that:</p>

<ol>
  <li>
    <p>The minimal polynomial of <script type="math/tex">A</script> splits into linear factors; moreover, each of its linear factors are distinct.</p>
  </li>
  <li>
    <p>If the minimal polynomial <script type="math/tex">p(x)</script> of <script type="math/tex">A</script> splits into distinct linear factors as <script type="math/tex">p(x) = \sum\limits_{k = 1}^{n} (x - \lambda_k)</script>, then <script type="math/tex">\operatorname{null}(A - \lambda_k I) = \operatorname{image}(q_k(A))</script> where <script type="math/tex">q_k(x) := (x - \lambda_k)^{-1}p(x)</script> for all <script type="math/tex">1 \leq k \leq n</script>.</p>
  </li>
  <li>
    <p>If the minimal polynomial <script type="math/tex">p(x)</script> of <script type="math/tex">A</script> splits into distinct linear factors as <script type="math/tex">p(x) = \sum\limits_{k = 1}^{n} (x - \lambda_k)</script>, then <script type="math/tex">E_k</script> denotes an orthogonal projection onto the eigenspace of eigenvalue <script type="math/tex">\lambda_k</script> of <script type="math/tex">A</script> eigenvalue where <script type="math/tex">E_k := (q_k(\lambda_k))^{-1} q_k(A)</script> and <script type="math/tex">q_k(x) := (x - \lambda_k)^{-1}p(x)</script> for all <script type="math/tex">1 \leq k \leq n</script>; moreover, <script type="math/tex">\sum\limits_{k=1}^{n} E_k = I</script>.</p>
  </li>
</ol>

<p>Assuming that these three propositions hold in this context, then it is clear that <script type="math/tex">A = A(I) = A \left(\sum\limits_{k=1}^{n} E_k \right) = \sum\limits_{k=1}^{n} A E_k = \sum\limits_{k=1}^{n} \lambda_k E_k</script>, and hence has its spectral decomposition as desired.
I would now like to show that these three propositions, necessary to deduce that <script type="math/tex">A</script> has its spectral decomposition, are indeed true in this context:</p>

<ol>
  <li>If <script type="math/tex">A</script> is a real symmetric matrix, then it can also be interpreted as a Hermitian matrix whose entries all happen to be real. It turns out that for any Hermitian matrix, all of its eigenvalues are real. Hence, not only does the minimal polynomial of <script type="math/tex">A</script> interpreted as a Hermitian matrix split into linear factors, as does the minimal polynomial of any matrix with entries in an algebraically closed field such as the field of complex numbers, but moreover all of its roots are real. Ultimately, since all of the roots of the minimal polynomial of <script type="math/tex">A</script> interpreted as a Hermitian are real, then it is guaranteed that the minimal polynomial of <script type="math/tex">A</script> viewed as a real symmetric matrix will split into linear factors as well (without needing to extend the field that <script type="math/tex">A</script> takes entries in to include the complex numbers). Therefore, the minimal polynomial of <script type="math/tex">A</script> splits into linear factors, as desired.</li>
</ol>

<p>Now, suppose that <script type="math/tex">\lambda</script> is any eigenvalue of <script type="math/tex">A</script> such that<script type="math/tex">(x - \lambda)^2</script> divides the minimal polynomial <script type="math/tex">p(x)</script> of <script type="math/tex">A</script>, and that <script type="math/tex">p(x) = (x - \lambda)^2 q(x)</script>. Then, for any vector <script type="math/tex">v \in \mathbb{R}^{d}</script> , <script type="math/tex">\langle (A - \lambda I)^2 q(A)v, q(A)v \rangle = \langle (A - \lambda I)q(A)v, (A - \lambda I)q(A)v \rangle = 0</script> since <script type="math/tex">A</script> is symmetric and hence self-adjoint; and, by properties of inner products, this implies<script type="math/tex">(A - \lambda I)q(A)v = 0</script>, which means that in fact <script type="math/tex">p(x)</script> cannot be the minimal polynomial of <script type="math/tex">A</script> as assumed since <script type="math/tex">v</script> is arbitrary. It follows that there cannot be any eigenvalues of <script type="math/tex">\lambda</script> of <script type="math/tex">A</script> such that <script type="math/tex">(x - \lambda)^{2}</script> divides the minimal polynomial of <script type="math/tex">A</script>. Hence, not only does the minimal polynomial of <script type="math/tex">A</script> split into linear factors, but moreover all of the factors of the minimal polynomial of <script type="math/tex">A</script> are distinct.</p>

<ol>
  <li>Assume that the minimal polynomial <script type="math/tex">p(x)</script> of <script type="math/tex">A</script> splits into distinct linear factors as <script type="math/tex">p(x) = \sum\limits_{k = 1}^{n} (x - \lambda_k)</script>, and select any particular <script type="math/tex">k</script> where <script type="math/tex">1 \leq k \leq n</script>.</li>
</ol>

<p>Firstly, select any eigenvector <script type="math/tex">v \in \operatorname{null}(A - \lambda_k I)</script> for <script type="math/tex">A</script> with eigenvalue <script type="math/tex">\lambda_k</script>. It turns out that since <script type="math/tex">v</script> is an eigenvector for <script type="math/tex">A</script>, <script type="math/tex">v</script> will be an eigenvector for any polynomial in <script type="math/tex">A</script> as well; in particular, in this context it turns out that <script type="math/tex">v</script> is an eigenvector for <script type="math/tex">q_k(A)</script> where <script type="math/tex">q_k(x) := (x - \lambda_k)^{-1}p(x)</script>, since <script type="math/tex">v</script> is an eigenvector for <script type="math/tex">A</script> and <script type="math/tex">q_k(A)</script> is a polynomial in <script type="math/tex">A</script>. Furthermore, in this context <script type="math/tex">v = \sum\limits_{c = 1}^{d} a_c e_c</script> for coefficients <script type="math/tex">a_c \in \mathbb{R}</script> for all <script type="math/tex">1 \leq c \leq d</script>, because <script type="math/tex">v \in \operatorname{null}(A - \lambda_k I)</script> and <script type="math/tex">\operatorname{null}(A - \lambda_k I)</script> is a subspace of <script type="math/tex">\mathbb{R}^{d}</script>. Hence <script type="math/tex">q_k(A)\left ( \sum\limits_{c = 1}^{d} a_c e_c \right ) = \sum\limits_{c = 1}^{d} a_c \left ( q_k(A) e_c \right) = q_k(\lambda_k)v</script>, which ultimately implies that <script type="math/tex">v \in \operatorname{image}(q_k(A))</script> since <script type="math/tex">\operatorname{image}(q_k(A)) = \operatorname{span}\left \{ q_k(A)e_c : 1 \leq c \leq d \right \}</script> and <script type="math/tex">v = \sum\limits_{c = 1}^d (q_k(\lambda_k)^{-1} a_c \left( q_k(A)e_c \right )</script>. Therefore <script type="math/tex">\operatorname{null}(A - \lambda_k I) \subseteq \operatorname{image}(q_k(A))</script> since <script type="math/tex">v</script> is arbitrary.</p>

<p>Now, select any vector <script type="math/tex">w \in \operatorname{image}(q_k(A))</script> (where <script type="math/tex">q_k(x) := (x - \lambda_k)^{-1}p(x)</script> as in the previous subcontext); this implies that <script type="math/tex">w = q_k(A)x</script> for some <script type="math/tex">x \in \mathbb{R}^{d}</script>. Clearly, <script type="math/tex">p(A)x = (A - \lambda_k I)q_k(A)x = 0</script>, because <script type="math/tex">p(x)</script> is the minimal polynomial of <script type="math/tex">A</script>. Since <script type="math/tex">(A - \lambda_k I)\left( q_k(A)x \right ) = (A - \lambda_k I)w = 0</script>, it follows that <script type="math/tex">w \in \operatorname{null}(A - \lambda_k I)</script>. Therefore <script type="math/tex">\operatorname{image}(q_k(A)) \subseteq \operatorname{null}(A - \lambda_k I)</script> since <script type="math/tex">w</script> is arbitrary.</p>

<p>Hence, <script type="math/tex">\operatorname{null}(A - \lambda_k I) = \operatorname{image}(q_k(A))</script> as desired, since <script type="math/tex">\operatorname{null}(A - \lambda_k I) \subseteq \operatorname{image}(q_k(A))</script> and <script type="math/tex">\operatorname{image}(q_k(A)) \subseteq \operatorname{null}(A - \lambda_k I)</script>. Therefore, it ultimately follows that <script type="math/tex">\operatorname{null}(A - \lambda_j I) = \operatorname{image}(q_j(A))</script> for all <script type="math/tex">1 \leq j \leq n</script> since <script type="math/tex">k</script> is arbitrary as well.</p>

<ol>
  <li>As in the previous subcontext, assume that the minimal polynomial <script type="math/tex">p(x)</script> of <script type="math/tex">A</script> splits into distinct linear factors as <script type="math/tex">p(x) = \sum\limits_{k = 1}^{n} (x - \lambda_k)</script>, and select any particular <script type="math/tex">k</script> where <script type="math/tex">1 \leq k \leq n</script>. Now, select any vector <script type="math/tex">v \in \operatorname{null}(A - \lambda_k I) = \operatorname{image}(E_k)</script>: it is straightforward to verify that <script type="math/tex">E_k v = q_k(\lambda_k)^{-1} q_k(A) v = q_k(\lambda_k)^{-1} q_k(\lambda_k) v = v</script>, and furthermore that <script type="math/tex">E_k^{2} v = E_k (E_k v) = E_k v = v</script>. It turns out that <script type="math/tex">\operatorname{null}(E_k) = \operatorname{image}^{\perp}(E_k) = \operatorname{null}^{\perp}(A - \lambda_k I)</script>, since eigenvectors with distinct eigenvalues are orthogonal for any real symmetric such as <script type="math/tex">A</script>; please see e.g. my Quora answer (http://1. How do I prove that eigenvectors corresponding to distinct eigenvalues of a real symmetric matrix are orthogonal? (https://www.quora.com/How-do-I-prove-that-eigenvectors-corresponding-to-distinct-eigenvalues-of-a-real-symmetric-matrix-are-orthogonal)) on the matter for a further justification of this fact. Hence <script type="math/tex">E_k</script> is an orthogonal projection. Therefore, it ultimately follows that each <script type="math/tex">E_j</script> is an orthogonal projection for all <script type="math/tex">1 \leq j \leq n</script> as desired, since the choice of <script type="math/tex">k</script> here is arbitrary.</li>
</ol>

<p>Lastly, it turns out that the set of polynomials <script type="math/tex">S = \left \{ q_k(\lambda_k))^{-1} q_k(x) : 1 \leq k \leq n \right \}</script>is coprime. Since <script type="math/tex">S</script> is a set of coprime polynomials in <script type="math/tex">\mathbb{R}[x]</script>, it follows from the analogue of Bézout’s identity for polynomials in <script type="math/tex">\mathbb{R}[x]</script> that <script type="math/tex">\sum\limits_{k=1}^{n} a_k(x) \left( q_k(\lambda_k))^{-1} q_k(x) \right) = 1</script> for some polynomials <script type="math/tex">a_k(x) \in \mathbb{R}[x]</script> for all <script type="math/tex">1 \leq k \leq n</script>; this implies that <script type="math/tex">\sum\limits_{k=1}^{n} a_k(A) \left( q_k(\lambda_k))^{-1} q_k(x) \right) = \sum\limits_{k=1}^{n} a_k(A) E_k = I</script>. Moreover, we have that for all <script type="math/tex">1 \leq j \leq n</script>, <script type="math/tex">E_j \left( \sum\limits_{k=1}^{n} a_k(A) E_k \right) = a_j(A) E_j^{2} = E_j</script>; this implies that <script type="math/tex">a_j(A) = 1</script> for <script type="math/tex">1 \leq j \leq n</script> since each <script type="math/tex">E_j</script> is idempotent. Therefore, it ultimately follows that <script type="math/tex">\sum\limits_{k=1}^{n} E_k = I</script> as desired.
In conclusion, it follows that <script type="math/tex">A</script> indeed has its spectral decomposition <script type="math/tex">A = \sum\limits_{k = 1}^{n} \lambda_k E_k</script> as desired, since the three propositions needed to establish that <script type="math/tex">A</script> has its spectral decomposition have been shown to hold in this context. Therefore, any real symmetric matrix has its spectral decomposition as desired, since <script type="math/tex">A</script> arbitrary; and hence the adjacency matrix of any simple graph has its spectral decomposition as desired, since adjacency matrices of simple graphs are just special instances of real symmetric matrices.</p>

  </div>

  
</article>
      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Mark Farrell</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Mark Farrell
            
            </li>
            
            <li><a href="mailto:m4farrel@uwaterloo.ca">m4farrel@uwaterloo.ca</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
